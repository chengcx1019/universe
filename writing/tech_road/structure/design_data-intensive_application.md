## 构建数据密集型应用(Designing Data-Intensive Application)



**第一部分：数据系统的基石**

讨论设计数据密集型应用所依赖的基本思想

数据密集型体现在三个方面，数据的量，复杂度及数据变化的速度

- 第一章：可靠性、可扩展性、可维护性

  - 讨论我们实际要到达的目标：可靠性(Reliability)，可扩展型(Scalability)，可维护性(Maintainability)；
  - 我们该如何思考这些概念；
  - 以及如何实现他们

- 第二章：数据模型与查询语言

  比较不同的数据模型和查询语言，看看他们如何适用于不同的场景

- 第三章：存储与检索

  讨论存储引擎：数据库如何在磁盘上摆放数据，以及如何高效地再次找到它

- 第四章：编码与演化

  数据编码（序列化），以及随时间演化的模式。

**第二部分：分布式数据**

讨论存储在一台机器上的数据转向讨论分布在多台机器上的数据，这对于可扩展性是必须的，但带来各种独特的挑战

- 第五章：复制

- 第六章：分区

- 第七章：事务

- 第八章：分布式系统的麻烦

  探索关于分布式系统的更多细节

- 第九章：一致性与共识

  分布式系统中实现一致性与共识意味着什么
  **第三部分：衍生数据**

讨论那些从其他数据集衍生出一些数据集的系统。衍生数据经常出现在异构系统中：当没有单个数据库可以把所有事情都做的很好时，应用需要集成几种不同的数据库，缓存，索引等。

- 第十章：批处理

- 第十一章：流处理

- 第十二章：数据系统的未来

  讨论在将来构建可靠，可伸缩和可维护的应用程序



### 第一部分：数据系统的基石

讨论设计数据密集型应用所依赖的基本思想

#### 第一章：可靠性、可扩展性、可维护性

数据密集型应用通常由标准组件构成，标准组件提供了很多通用功能：

- 数据库

- 消息队列

- 缓存

- 搜索索引

- 流处理

- 批处理

  ![](/media/files/images/sc_45.png)

- ##### 可靠性

- ##### 可扩展性

  ###### 负载

  推特业务为例

  - 发布推文

    ![](/media/files/images/sc_46.png)

  - 主页时间线

    ![](/media/files/images/sc_47.png)

  **在早期创业公司或非正式产品中，通常支持产品快速迭代的能力要比可扩展至未来的假想负载要重要的多。**

- 可维护性

  - 可操作性（Operability）
  - 简单性(Simplicity)
  - 可演化性(Evolability)

#### 第二章：数据模型与查询语言

比较不同的数据模型和查询语言，看看他们如何适用于不同的场景

- 关系数据库与文档数据库对比

  当存在多对多关系时，需要在应用程序代码中模拟连接，这通常会比数据库内的专用代码执行的连接慢。

**数据查询语言**

- web上的声明式查询

  在web浏览器中，使用声明式css样式比使用js命令式的操作样式要好的多，类似地，在数据库中，使用sql这样的声明式查询语言比使用命令式查询api要好。

- mapreduce查询

  mapreduce在分布上查询上并不具有垄断

  编程模型

- 图数据模型

#### 第三章：存储与检索

讨论存储引擎：数据库如何在磁盘上摆放数据，以及如何高效地再次找到它。

事务性负载和分析性负载（列存储）

两大类存储引擎：

- 日志结构(log-structured)
- 面向页面(page-oriented)

##### 驱动数据库的数据结构

**索引**是从主数据衍生的附加结构，维护额外的结构会产生开销，特别是在写入时。任何类型的索引通常都会减慢写入的速度，因为每次写入数据时都需要更新索引

- 哈希索引

- SSTables（Sorted String Table） and LSM-Trees

- BTree

  比上面3者更为常用

- 事务处理和分析系统

  ![](/media/files/images/sc_48.png)

- 数据仓库

  数据仓库包含公司所有各种OLTP系统中的只读数据副本。从OLTP数据库中提取数据（使用定期的数据转储或连续的更新流），转换成适合分析的模式，清理并加载到数据仓库中。

  将数据存入仓库的过程称为“抽取-转换-加载”(ETL)

- OLTP数据库和数据仓库之间的分歧

![](/media/files/images/sc_49.png)

- 数据仓库

  - 下钻：统计维度降到更低的层次，如从季度到月份，数据更细致
  - 上卷：下钻反过程，汇总数据
  - 切片：某些维度固定值
  - 切块：某些维度固定区间

- 星型和雪花型：分析的模式

  星型：![](/media/files/images/sc_50.png)

- 列存储

  Parquet【57】

  Vertical【62】

  OLTP数据库和文档数据库存储都是以面向行的形式进行布局

  > Cassandra和HBase从Bigtable继承，仍然是面向行的

  - 写入列存储

#### 第四章：编码与演化

数据编码（序列化），以及随时间演化的模式。

几种编码数据的格式，包括JSON，XML，Protocol Buffers，Thrift和Avro，以及这些格式如何应对模式变化，及利用这些格式进行数据存储和通信：REST，RPC（Remote Procedure Call，远程过程调用）以及消息传递系统（actors和消息队列）。

使用某种语言的内置编码通常不是一个好主意。

- 向前和向后兼容性

##### 数据如何在流程之间流动的一些最常见的方式

- 数据库中的数据流

  微服务架构：一个关键的设计目标就是通过使服务独立部署和演化来使应用程序更易于更改和维护。

- web service

  - REST，SOAP

    > 在编程中，一个幂等操作的特点是任意多次执行所产生的影响与一次执行的影响相同；幂等函数或幂等方法是指可以用相同方法重复运行，并能获得相同结果的函数。

    - REST强调简单的数据格式，使用url来标示资源，并使用http功能进行缓存控制，身份验证和内容协商

  - RPC

  - 异步消息传递

### 第二部分：分布式数据

讨论存储在一台机器上的数据转向讨论分布在多台机器上的数据，这对于可扩展性是必须的，但带来各种独特的挑战。

导致需要将数据分布到多台机器上有多种多样：可扩展性，容错/高可用性，延迟等

##### 扩展至更高的载荷

- 共享架构

  - 共享内存

  - 共享磁盘架构

    机器使用独立的处理器和内存，但是数据存储在机器之间共享的磁盘阵列上，这些磁盘通过快速网络连接（网络附属存储，NAS；存储区网络SAN）

- 无共享架构

  有时称为水平扩展，每个节点只使用各自的处理器，内存和磁盘。节点之间的任何协调，都是在软件层面使用传统网络实现的。

- 复制VS分区

  - 复制

    在几个不同的节点上保存数据的相同副本。复制提供了冗余：如果一些节点不可用，剩余的节点仍然可以提供数据服务。

  - 分区

    将一个大型数据库拆分成较小的子集，从而不同的分区可以指派给不同的节点。



#### 第五章：复制

同步不同的复制数据间的更改

- 处理节点宕机
  - 从库失效：追赶恢复
  - 主库失效：故障转移

#### 第六章：分区

![](/media/files/images/sc_60.png)



#### 第七章：事务

如果没有事务处理，各种错误情况（进程崩溃，网络断电，停电，磁盘已满，意外并发等）意味着数据可能以各种方式变得不一致。

- 你是否需要事务

- 几个广泛使用的隔离级别：

  **事务隔离的4个级别**

  - 读未提交（基本不用）
  - 读已提交
  - 快照隔离/可重复读
  - 可序列化

- 竞争条件的各种例子

  - 脏读(dirty  reads)

    定义：一个客户端读取到另一个客户端尚未提交的写入

    方法：读已提交或更强的隔离级别可以防止脏读

  - 脏写(dirty  writes)

    定义：一个客户端覆盖写入了另一个客户端尚未提交的写入

    方法：几乎所有的事务实现都可以防止脏写

  - 读取偏差（**不可重复读**）(read skew/nonrepeatable  reads)

    定义：在同一个事务中，客户端在不同的时间点会看见数据库的不同状态。

    方法：快照隔离经常用于解决这个问题，它允许事务从一个特定时间点的一致性快照中读取数据。通常使用多**版本并发控制（MVCC）**来实现

    注：同一个事务中多次读取同样记录结果是一致的（记录指具体的数据行）

  - 更新丢失(lost updates)

    定义：两个客户端同时执行读取-修改-写入序列，其中一个写操作，在没有合入另一个写入变更情况下，直接覆盖了另一个写操作的结果，所以导致数据丢失。

    方法：快照隔离的一些实现可以自动防止这种异常，而另些则需要手动锁定(select for update)。

  - 写偏差(write skew)

    定义：一个事务读取一些东西，根据读取的值作出决定，并将决定写入数据库，但是写入时候，决定的前提不再是真实的。

    方法：可序列化隔离才能防止这种异常。

  - 幻读(phantom reads)

    定义：一个事务读取符合某些搜索条件的对象，另一个客户端进行了影响搜索结果的写入。

    方法：快照隔离可以防止直接的幻像读取，但是在写偏差环境下的幻象读取需要特殊处理，例如索引锁定。
  
    注：可重复读未何可以保证同一个事务内读取具体行的结果是一致的，却无法保证一定目标范围内的数据是一致的？理解这个问题需要清楚锁加的对象是什么，读写某条记录，申请的锁是可能是某个具体对象（即具体的数据行），也可能是锁一定范围（如果事务1获取范围锁，事务2操作目标范围，发现目标范围被锁，陷入阻塞），也可能锁整表

  

  弱隔离级别可以防止这些异常情况的一部分，剩下的需要应用程序的开发者手动处理这些情况，只有可序列化的隔离才能防范所有这些问题。

  

  ##### 事务隔离级别的实现

  几种不同的锁：读锁，写锁、范围锁

  ###### 读已提交
  
  读锁仍然在一个原子操作完成后立即释放；写锁从写操作开始持有，事务提交后释放。
  
  ###### 快照隔离
  
  基本想法：每个事务都从数据库的一致快照中读取，即使这些数据随后被其他事务更改，每个事务也只能看到该特定时间点的旧数据。
  
  实现：MVCC 多版本并发控制
  
  - 悲观策略：串行化
  
    **读锁、写锁从读、写操作开始持有，事务提交后释放**。与读已提交的区别是，读锁也在事务提交后释放。
  
  - 乐观策略：多版本+检测冲突
  
    事务独立读取快照，，提交时检测「修改的其他快照」与当前数据是否有冲突
  
  
  
  ###### 可序列化事务的三种不同实现方法：
  
  ​	可序列化是最高的隔离级别，强制事务序列化执行，可序列化实现：**从各操作开始前持有读锁、写锁、范围锁，直到事务提交后释放**。
  
  - 字面意义上的串行执行
  
    如果每个事务的执行速度非常快，并且事务吞吐量足够低，足以在单个cpu核上处理，这是一个简单而有效的选择。
  
  - 两阶段锁定(teo-phase locking)
  
    实现可序列化的标准方式，但是许多应用出于性能问题的考虑避免使用它。
  
  - 可串行化快照隔离(Serializable Snapshot Isolation, SSI)
  
    允许事务执行而无需阻塞。当一个事务想要提交时，它会进行检查，如果没有序列化，事务就会被中止。【检查有没有序列化的标准是什么，如何进行检查的】
  
  



##### mysql的事务隔离级别

| 级别名   | 级别号 | 脏读 | 不可重复读 | 幻读 |
| -------- | ------ | ---- | ---------- | ---- |
| 读未提交 | 0      | 1    | 1          | 1    |
| 读提交   | 1      | 0    | 1          | 1    |
| 可重复读 | 2      | 0    | 0          | 1    |
| 可串行化 | 3      | 0    | 0          | 0    |

MySQL的默认隔离级别是可重复读，解决了脏读、部分不可重复读问题，有幻读问题。

读未提交什么都无法保证，读提交可以避免脏读（事务B读取了事务A尚未提交的数据），可重复读可以消除不可重复读（事务A在两次查询的间隙，值被事务B操作改变，此时事务B已提交，A两次的读取出现不一致），但仍会出现幻读，可序列化可以避免这些问题





#### 第八章：分布式系统的麻烦

探索关于分布式系统的更多细节

分布式系统中可能发生的各种问题：

- 尝试通过网络发送数据包时，数据包可能丢失或任意延迟。同样，回复也可能会丢失或延迟，所以如果没有得到答复，你不知道消息是否通过。
- 节点的时钟可能会与其他节点明显不同步，可能会突然跳转或跳回，因为不能很好的衡量时钟错误间隔，所以依赖它是很危险的
- 一个进程可能会在其执行的任何时候暂停一段很长的时间，被其他节点宣告死亡，然后再次复活，却没有意识到它被暂停了。

每当软件软件试图做任何涉及其他节点的事情，偶尔就有可能会失败，或者随机变慢，或者根本没有响应。在分布式系统中，我们试图在软件中建立部分失效的容错机制，这样整个系统即使在某些组成部分被破坏的情况下，也可以继续运行。

- 检测错误
- 如何容忍

从不可靠的组件构建可靠的系统

- 网络的问题

- 时钟和时序问题

- 可以避免的程度

- 进程的不可靠性

- 如何思考一个分布式系统的状态

  分布式系统可以永久运行而不会在服务层面中断，因为所有的错误和维护都可以在节点级别进行处理。

#### 第九章：一致性与共识

分布式系统中实现一致性与共识意味着什么

达成共识意味着以这样一种方式决定某件事：所有节点一致同意所做决定，且这一决定不可撤销。很广泛的一系列问题都可以归结为共识问题，并且彼此等价，这些等价的问题包括：

- 线性一致性的CAS寄存器

  寄存器需要给予当前值是否等于操作给出的参数，原子的决定是否设置新值

- 原子事务提交

  数据库必须决定是否提交或中止分布式事务

- 全序广播

  消息系统必须决定传递消息的顺序

- 锁和租约

  当几个客户端争抢锁或租约时，由锁决定哪个客户成功获得锁。

- 成员/协调服务

  给定某种故障检测器（例如超时），系统必须决定哪些节点活着，哪些节点因为会话超时需要被宣告死亡。

- 唯一性约束

  当多个事务同时尝试使用相同的健创建冲突记录时，约束必须决定哪一个被允许，哪些因为违反约束而失败。

选取新领导的三种方法：

- 等待领导者恢复
- 人工故障切换
- 使用算法自动选择一个新的领导者





### 第三部分：衍生数据

讨论那些从其他数据集衍生出一些数据集的系统。衍生数据经常出现在异构系统中：当没有单个数据库可以把所有事情都做的很好时，应用需要集成几种不同的数据库，缓存，索引等。

应用程序通常组合使用多种组件：数据存储，索引，缓存，分析系统等等，并实现在这些组件中移动数据的机制。



从更高的层次看，存储和处理数据的系统可以分为两大类

- 记录系统

  真相源，持有数据的权威版本。

- 衍生数据系统

  是另一个系统中的现有数据以某种方式进行转换或处理的结果。典型的例子是缓存，索引和物化视图亦属此类。

#### 第十章：批处理

基于一个假设：输入是有界的，即已知和有限的大小

主要有三种不同类型的系统

- 服务（在线系统）
- 批处理系统（离线系统）
- 流处理系统（准实时系统）

批处理算法：Map-Reduce



##### 使用Unix工具进行批处理

- unix工具

  看一个操作实例

  - awk

  - grep

  - uniq

    通过检查两个相邻行是否相同来过滤掉输入中的重复行，-c表示输出一个计数器

  - sort

    -n 按每行起始处的数字排序，-r 然后逆序返回结果

- 排序VS内存中的聚合

  hash表和排序的性能取决于不同URL的数量

  - 如果作业的工作集大于可用内存，则排序方法的优点是可以高效的使用磁盘，数据块可以在内存中排序并作为段文件写入磁盘，然后多个排序好的段可合并为一个更大的排序文件。
  - **sort程序通过溢出至磁盘的方式来自动应对大于内存的数据集，并能同时使用多个CPU核进行并行排序**。

- Unix哲学

  - 统一的接口

    文件

    xargs可以指定如何解析输入

  - 逻辑与布线相分离

    将输入/输出与程序逻辑分开，可以将小工具组合成更大的系统，但是**标准的输入和输出能够做的事是非常有限的**。

  - 透明度与实验

unix工具的最大局限在于它们**只能在一台机器上运行**



##### MapReduce和分布式文件系统

- MapReduce作业执行

  - 读取一组输入文件，并将其分解成记录
  - 调用Mapper函数，从每条输入记录中提取一对键值，类似awk提取url作为key
  - 按key排列所有的键值对
  - 调用Reduce函数遍历排序后的键值对。如果同一个键出现多次，排序使它们在列表中相邻，所以很容易组合这些值而不必在内存中保留很多状态。

  **注意**：

  为了确保具有相同键的所有键值对最终落在相同的Reduce处，框架使用**键的散列值**来确定Reduce任务应该接收到特定的键值对。



键值对必须进行排序，但数据集可能太大，无法在单台机器上使用常规排序算法进行排序，排序是分阶段进行的：首先每个Mapper都按照散列值将输出分区到Reducer，分区到每一个Reducer的数据都分别在Mapper的本地磁盘上写入了一个排序的文件中，只要当Mapper读取完输入文件，并写入到排好序的文件中，此时Reducer从每个Mapper取回（下载）分区到自己的排序文件，整个分区，排序，取回排序文件的过程称为混洗（shuffle）。

> 一旦你有一个合适的键值散列函数，你可以为每个分区分配一个散列范围（而不是键的范围），每个通过哈希散列落在分区内的键将被存储在该分区中。

```java
package com.jzguo3.guava.utilites;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.locks.Lock;

public class MyHashMap<T, V> {
    private Map<T, V> myMap;
    private Lock lock;

    public MyHashMap(Map<T, V> myMap) {
        this.myMap = new HashMap<>();
    }

    public V get(T key) {
        try{
            lock.lock();
            return myMap.get(key);
        }finally {
            lock.unlock();
        }
    }

    public void put(T key, V value) {
        try {
            lock.lock();
            myMap.put(key, value);
        }finally {
            lock.unlock();
        }
    }
}
```







> 像归并排序一样，对那些已经排好序的文件，并排读取输入文件，查看每文件的第一个键，根据排序规则，复制最低键到输出文件，重复直到合并所有文件到同一文件。

- MapReduce工作流

  单个MR作业解决的问题非常有限，因此将MR作业连接成为工作流是极为常见的。这个链接通过目录名隐式实现。

  - Hadoop的工作流调度器：Oozie，Azkaban，Luigi，Airflow和Pinball
  - Hadoop的各种高级工具pig，Hive，Cascading，Crunch和FlumeJava也支持构建组合多个MR作业的工作流

- Reduce端连接与分组

  mapreduce的连接算法

  - 排序合并连接

    每个Mapper提取的键一样，但是值可能是不一样的Ts

- Map端连接

  - 广播散列连接

    broadcast可以解释为，更大输入在每个Mapper的分区被Mapper完全的读进内存中

  - 分区散列连接

  - Map端合并连接

  - MapReduce工作流与Map端连接

- 批处理工作流的输出

  批处理过程的输出通常不是报表，而是一些其他类型的结构

  - 建立搜索索引：文件关键词字典，关键字及包含关键字的所有文档id列表

  - 键值存储：构建机器学习系统

    - 分类器，比如垃圾邮件过滤器，异常检测，图像识别
    - 推荐系统，你可能认识的人，你可能感兴趣的产品或相关的搜索

  - 批处理输出的哲学

    很多Unix上表现良好的设计原则似乎也适用于Hadoop，但Unix和Hadoop在某些方面也有所不同，Hadoop上可以通过使用更结构化的文件格式消除一些低价值的语法转换，比如**Avro和Parquet——提供了就业模式的高效编码，并允许模式随时间推移而演进**

- Hadoop与其他分布式数据库的对比

  - 存储多样性
  - 处理模型多样性

- 针对频繁故障设计

  任意终止进程的自由有利于提高计算集群中资源利用率

  Yarn的CapacityScheduler支持抢占以平衡不同队列的资源分配

##### MapReduce之后

- 中间状态的物化视图

  一个作业的输出是另一个作业的输入，那么这个输出就是一个中间状态，将中间状态写入文件的过程称为物化

  mapreduce的不足：

  1. 作业之间存在依赖关系
  2. mapper通常是多余的
  3. 中间状态也会被复制到多个节点

  - 数据流引擎

    - spark
    - Tez
    - Flink

    以上三种引擎的设计方式与很多区别，但有一个共同点：把整个工作流作为单个文件处理，而不是把它分解为独立的子作业

- 图和迭代处理

- 高级接口和语言



#### 第十一章：流处理

限制一个架构最大负载量的限制是什么

docker构建spark环境



##### 传递事件流

- 消息系统

- 分区日志


##### 数据库与流

- 保持系统同步

- 获取数据变更

- 事件溯源

- 状态、流和不变性


##### 流处理

- 流处理的应用
- 时间推理
- 流连接
- 容错





**流是指随着时间推移逐渐可用的数据**

事件流视为一种数据管理机制，无界限，增量处理。

##### 消息系统

表示、存储、通过网络传输流

流和数据库之间的关系

连续处理流的方法和工具，用于应用构建的方式



**流处理的几种目的**：

- 搜索事件模式（复杂事件处理）
- 计算分窗聚合（流分析）
- 保证衍生数据系统处于最新状态（物化视图）



流处理中可能出现的三种连接类型：（straem join）

- 流流连接

  两个输入流都由活动事件组成

- 流表连接

  一个输入流由活动事件组成，另一个数据流是数据库变更日志

- 表表连接

  两个输入流都是数据库变更日志



流处理中实现容错和恰好一次语义（exactly-once semantics）的技术



#### 第十二章：数据系统的未来

实然-应然



数据集成

理解数据流



批处理与流处理





讨论在将来构建可靠，可伸缩和可维护的应用程序



如何使用批处理和流处理来解决数据集成问题，以便让数据变更在不同系统间流动

维护索引，物化视图，机器学习模型，统计摘要





**软件和数据对世界产生了如此巨大的影响，我们工程师必须牢记，我们有责任为我们想要的世界而努力：一个尊重人们，尊重人性的世界。**



### 案例

#### 知乎架构变迁史

- PV(page view)，即页面浏览量，或点击量;通常是衡量一个网络新闻频道或网站甚至一条网络新闻的主要指标。pv就是一个访问者打开了你的几个页面。
- uv(unique visitor)，指访问某个站点或点击某条新闻的不同IP地址的人数。
- PR值，即PageRank，网页的级别技术。取自Google的创始人Larry Page，它是Google排名运算法则(排名公式)的一部分，用来标识网页的等级/重要性。级别从1到10级，10级为满分。PR值越高说明该网页越受欢迎(越重要)。
- IP(独立IP)：即Internet Protocol,指独立IP数。



#### Docker核心技术与实现原理

- 命名空间 (namespaces)

  运行在同一台机器上的不同服务能做到**完全隔离**，就像运行在多台不同的机器上一样。

  命名空间为新创建的进程隔离了文件系统、网络，并与宿主机器之间的进程相互隔离

  - 进程

  - 网络

    - Host

    - Container

    - None

    - Bridge

      当 Docker 服务器在主机上启动之后会创建新的虚拟网桥 docker0，随后在该主机上启动的全部服务在默认情况下都与该网桥相连

      - libnetwork

        提供了一个连接不同容器的实现，同时也为应用给出一个能够提供一致的编程接口和网络层抽象的容器网络模型

        - Sandbox

          存储着当前容器的网络栈配置，包括容器的接口、路由表和 DNS 设置，Linux 使用网络命名空间实现这个 Sandbox，每一个 Sandbox 中都可能会有一个或多个 Endpoint，在 Linux 上就是一个虚拟的网卡 veth，Sandbox 通过 Endpoint 加入到对应的网络中，这里的网络可能就是我们在上面提到的 Linux 网桥或者 VLAN

        - Endpoint

        - Network

  - 挂载点

- 控制组（CGroups）

  命名空间不能提供物理资源上的隔离，比如CPU或者内存

- UnionFS（存储驱动）

  后来改到AUFA，目前采用overlay2取代了aufs成为了推荐的存储驱动

  把多个文件系统『联合』到同一个挂载点的文件系统服务

  docker的镜像是如何组织的：每一层镜像都建立在另一层镜像之上，并且镜像都是只读的，每当基于一个镜像新建一个容器时，等于在镜像的最上层添加一个可以读写的层。

- reference

  https://draveness.me/docker





#### Docker入门与实践

> mac版的docker网络配置，mac版封装好了用xhyve创建的虚拟机，这台虚拟机才是docker的宿主机。

https://yq.aliyun.com/articles/40494?spm=a2c4e.11153959.teamhomeleft.95.44ab18b1OELKiS

[mac的例外之处](https://docs.docker.com/docker-for-mac/networking/#use-cases-and-workarounds)

宿主机无法直接和容器互ping，但是可以进行端口xport映射，从而通过localhost:xport访问容器内的服务

- docker run -d -it --rm ubuntu bash 

  - `-it`：这是两个参数，一个是 `-i`：交互式操作，一个是 `-t` 终端。我们这里打算进入 `bash` 执行一些命令并查看返回结果，因此我们需要交互式终端。
  - `--rm`：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 `docker rm`。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 `--rm` 可以避免浪费空间。

  - -d:此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 `docker logs`查看)

- docker commit

- ```bash
  docker commit \
      --author "Changxin Cheng <chengcx1019@gmail.com>" \
      --message "添加了pyspark，可通过python接口调用spark服务" \
      nodemaster \
      sparkbase:v2
  ```

- docker build .  --no-cache -t {image_name}

  - `-t`:镜像的命名和可选的tag标签可以以 'name:tag' 这种形式
  - `.`:代表当前上下文环境，docker引擎会打包上下文内的所有文件进行镜像构建

- docker system df

  查看镜像、容器、数据卷所占用的空间

- docker exec -i -t bash 

##### compose

`docker-compose`



先用docker搭一个zookeeper集群吧

容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。







## spark和hadoop

### spark

以指定版本启动spark:

​	PYSPARK_PYTHON=python3 ./bin/pyspark



jupyter toree install --interpreters=Scala --spark_home=/usr/local/Cellar/apache-spark/2.1.0/libexec --user --kernel_name=apache_toree --interpreters=PySpark,SparkR,Scala,SQL



jupyter扩展插件：

pip install jupyter_contrib_nbextensions
jupyter contrib nbextension install --user
pip install jupyter_nbextensions_configurator
jupyter nbextensions_configurator enable --user

##### spark用例

spark常用操作及实践

- 创建推荐引擎

  ALS协同过滤式推荐算法

  将mxn矩阵分解为mxrank 和rankxn

- 决策树二分类

  - 分类准则

    - 基尼指数：基尼指数最小
      $$
      G_i = 1 - \sum_{k=1}^{n}p_{i,k}^2
      $$
      式中$p_{i,k}$是第i个节点中类别k的比率

    - 熵：选择分裂后熵最小的方式，自然全部分类正确的话熵为0
      $$
      H_i = - \sum_{k=1,p_{i,k}\neq0}^{n}p_{i,k}\log(p_{i,k})
      $$




### hadoop

#### 操作

- 从本地复制文件到hdfs：`hadoop fs -compFromLocal -f sorce dest`


#### 故障排除

- hdfs拒绝连接

  格式化hdfs：`hdfs namenode -format`

- 

