> 计算机体系结构及系统设计

## 计算机体系结构



### 故障排查：顺便考察linux指令

无法访问某网址

###  python语法

#### 模块结构

##### Abstract Base Classs

 `@abstractmethod `和`abstractproperty`decorator 只能在 metaclass 是(或者继承) `ABCMeta`的class中使用。

register(subclass),ABC不会出现在subclass的MRO (Method Resolution Order)中，但issubclass()是有效的

Mix-in class

duck-typing：

一种编程风格，不指定具体类型，允许多种形式的替代来提高灵活性，避免使用type()和isinstance()验证，而更多使用hasattr()及EAFP(Easier to ask for forgiveness than permission)编程。

EAFP:

一种通用编程风格，假定属性存在并直接使用，使用try，except来处理不存在的假设。

##### FAQ



##### parameters和arguments的区别

`parameters`是在函数定义时定义的，而`arguments`是在函数调用时传递给函数的值，parameters定义了函数可以接收arguments的类型。

##### 可变和不可变

操作一个可变对象(list, dict, set, etc)，所有指向对象的变量同时改变，而操作一个不可变对象(str, int, tuple, etc)，会产生一个新的对象，同时变量指向新的对象：

```python
>>>x = list() # list是可变对象
>>>y = x
>>>x.append(10)
>>>x
[10]
>>>y
[10]
>>>x = 5 # int是不可变对象
>>>y = x
>>>x = x + 1
>>>y
5
>>>x
6
```

使用is和id()来判断变量是否引用同一对象。

##### 复制一个对象

`copy()`或`deepcopy()`，序列的切片操作返回的是一个新的对象。

##### 查看对象的方法和属性

`dir(object)`。

##### '?:'操作符

`[on_true] if [expression] else [on_false]`

##### decorator装饰器

一个函数返回另一个函数。

```python
def f(...):
    ...
f = staticmethod(f)

@staticmethod
def f(...):
    ...
```

对某个函数使用decorator时保留该函数重要的元信息

##### descriptor描述器

定义了 __get__(), __set__(), or __delete__()中任意一个的对象。



### 

python语法核心

进程锁

dict底层实现

### 操作系统

#### 基础

- 通道作为一个独立于CPU的处理器，负责数据共享和传输处理的工作单元

  - 通道控制设备控制器，设备控制器控制设备

- 按记录的逻辑结构分，文件分为**堆文件、索引文件、索引顺序和顺序文件**

- MS-DOS 系统中的磁盘文件物理结构属于**链接文件**

- 批处理系统主要指**多道批处理系统**，由于多道程序能交替使用CPU，提高了CPU及其他系统资源的利用率，同时也提高了系统的效率。多道批处理系统的缺点是延长了作业的周转时间，用户不能进行直接干预，缺少交互性，不利于程序的开发与调试。

- 带宽：又叫频宽，是指在固定的的时间可传输的资料数量，亦即在传输管道中可以传递数据的能力。

- 位宽 ：位宽就是内存或显存一次能传输的数据量。

- **函数声明但函数未定义，编译可通过，链接不可通过**

- 孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

  僵尸进程将会导致资源浪费，而孤儿则不会。

#### 存储

- 随机存取方式是指CPU可以对存储器的任一存储单元中的内容随机存取，而且存取时间与存储单元的物理位置无关
  - CDROM即光盘，采用串行存取方式
  - EPROM，DRAM，SRAM采用随机存取方式

#### 共享与互斥

- 解决死锁的方法
  - 银行家算法：避免死锁
  - 资源有序分配法：预防死锁
  - 资源分配图化简法：检测死锁
  - 撤销进程法：解决死锁

#### 内存管理

- 在分页式、段式和段页式管理中，运行开销可能最大的是分页式管理，分页式存储管理可能将连续的指令放置在不同的页中，会发生换页式中断

- 内存管理方案

  - 覆盖技术：把程序划分为若干个功能上相对独立的程序段，按照其自身的逻辑结构使那些不会同时运行的程序段共享同一块内存区域。程序段先保存在磁盘上，当有关程序的前一部分执行结束后，把后续程序段调入内存，覆盖前面的程序段。 
  - 交换技术：在分时系统中，用户的进程比内存能容纳的数量更多，系统将那些不再运行的进程或某一部分调出内存，暂时放在外存上的一个后备存储区，通常称为交换区，当需要运行这些进程时，再将它们装入内存。
    - 

- 内存管理方式

  - 简单存储管理
    - 可变分区
      - 分配算法
        - 最佳适应：每次分配最小的内存，这种方法能使碎片尽量小；
        - 最坏适应：每次分配最大的内存；
        - 首次适应：地址由低到高，找出一个能满足要求的空闲分区给所需要的请求；
        - 循环首次适应：首次适应的变种，分配内存时，从上次找到的空闲区的下一个空闲处开始查找，该算法可以使得内存中空闲区域分布的较均匀。
  - 分页式存储管理：将程序逻辑地址空间划分为固定大小的页(page)，而物理内存划分为同样大小的页框(page frame)。为方便地址转换，页面大小应是2的整数幂。每一个作业有一个页表，用来记录各个页在内存中所对应的块（页框）。
    - 地址组成：页号+页内偏移
    - 快表，又称联想寄存器(TLB)，用来存放当前访问的若干页表项，以加速地址变换的过程。
  - 请求式分页存储管理，在页式存储管理的基础上，增加了请求调页功能和页面置换功能
    - 页面置换算法
      - 最佳算法（OPT算法）：用来评价其他算法，使用缺页中断率：`f = F / A`（其中F为作业失败访问的次数，A为作业总的访问次数）
      - 先进先出算法（FIFO算法）：淘汰在内存驻留时间最长的页面
      - 最近最久未使用淘汰算法（LRU算法）：淘汰最久没有被使用的页面
      - 最不经常使用淘汰算法（LFU算法）：淘汰一段时间内，访问次数最少的页面。
  - 段式存储管理：段式存储管理要求每个作业的地址空间按照程序自身的逻辑划分为若干段，每个段都有一个唯一的内部段号。
  - 段页式存储管理：在段页式存储中，每个分段又被分成若干个固定大小的页。

- 地址重定位：逻辑地址转换成物理地址，这个过程称为地址重定位

  - 静态重定位：在装入作业时，装入程序把指令地址和数据地址全部转化为绝对地址，转换工作在作业执行前一次性完成。

  - 动态重定位：在程序执行时，配合重定位寄存器将相对地址转换为主存的绝对地址，更加灵活有效，不要给程序分配大片的连续空间，也能提供一个比主存大得多的地址空间

- 缓存

  - LRU最近最少使用算法：根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。

  - 主存到缓存的映射策略

    - 直接映射：一个内存地址能被映射到的Cache line是固定的

    - 全相联映射：主存中的一个地址可被映射进任意cache line

    - 组相联映射：将缓存分组，组内包含多块，组间采用直接映射，组内采用全相联映射

      例题帮助理解组相联映射，可跳过直接看解答。

    > 例题：容量为64块的Cache采用组相联方式映像，字块大小为128字节，每4块为一组，若主容量为4096块，且以字编址，那么主存地址为**（19）**位，主存区号为**（6）**位。
    >
    >
    >
    > 组相联的地址构成为：区号+组号+块号+块内地址,主存的每个分区/组大小与整个Cache大小相等，故此主存需要分的区数为：4096/64=64，因为2^6＝64，因此需要6位来表示区号。每4块为一组，故共有组数 64/4 = 16 ，因为2^4＝16，因此需要4位表示组号。每组4块，故表示块号需要2位。
    >
    > 块内地址共128字节，2^7＝128，所以块内地需要7位表示。所以：主存地址的位数＝6+4+2+7 ＝ 19

    假设某计算机按字编址，Cache有4个行，Cache和主存之间交换的块大小为1个字。若Cache的内容初始为空，采用2路组相联映射方式和LRU替换策略。访问的主存地址依次为0,4,8,2,0,6,8,6,4,8时，命中Cache的次数是**（3）**。

    2路组相联映射，即缓存分为两组，又缓存有4行，因而每组内分为2行，根据前面例题的启示，主存与缓存的**直接映射关系**应当为：组号= 主存地址%4/2（对4求余忽略区号），组内行号采用**全相联映射**，结合LRU算法，，那么我们可以得到下表：



    | 组号 | 缓存行号 | 0       | 4       | 8              | 2       | 0              | 6       | 8     | 6     | 4              | 8     |
    | ---- | -------- | ------- | ------- | -------------- | ------- | -------------- | ------- | ----- | ----- | -------------- | ----- |
    | 0组  | 0        | 0       | 0       | 8              | 8       | 8              | 8       | 8*    | 8*    | 8*             | 8**   |
    | 0组  | 1        |         | 4       | 4              | 4       | 0              | 0       | 0     | 0     | 4              | 4     |
    | 1组  | 0（3）   |         |         |                | 2       | 2              | 2       | 2     | 2     | 2              | 2     |
    | 1组  | 1（4）   |         |         |                |         |                | 6       | 6     | 6*    | 6*             | 6*    |
    | 备注 |          | 0%4/2=0 | 4%4/2=0 | 8%4/2=0，替换0 | 2%4/2=1 | 0%4/2=0，替换4 | 6%4/2=1 | 8命中 | 6命中 | 4%4/2=0，替换0 | 8命中 |

  - 替换策略

    - LRU最近最少使用

  - Cache的总容量包括：存储容量和标记阵列容量（有效位、标记位、一致性维护位和替换算法控制位）

    - 标记阵列中的有效位和标记位是一定有的，而一致性维护位（脏位）和替换算法控制位的取舍标准是看题眼

      ```
      假定主存地址为32位，按字节编址，主存和Cache之间采用直接映射方式，主存块大小为4个字，每字32位，采用回写（Write Back）方式，则能存放4K字数据的Cache的总容量的位数至少是【148K】
      
      按字节编址，块大小为4×32bit=16B=24B，则“字块内地址”占4位；“能存放4K字数据的Cache”即Cache的存储容量为4K字（注意单位），则Cache共有1K=2^10个Cache行，则Cache字块标记占10位；则主存字块标记占32-10-4=18位。
      
      题目中，明确说明了采用写回法，则一定包含一致性维护位，而关于替换算法的词眼题目中未提及，所以不予考虑。从而每个Cache行标记项包含18+1+1=20位，则标记阵列容量为：2^10*20位=20K位，存储容量为：4K*32位=128K位，则总容量为：128K+20K=148K位。
      
      ```

- 共享

  - 同步信号量的初值一般设为0；互斥信号量的初值一般设为1；
  - 临界资源是一次仅允许一个进程使用的共享资源
  - **每个进程中访问临界资源的那段程序称为临界区**
  - 活跃度失败
    - 饥饿：指线程需要访问的资源 被永久拒绝 ，以至于不能再继续进行。解决饥饿问题需要平衡线程对资源的竞争，如线程的优先级（如果每次来就执行优先级高的，那么优先级低的可能永远执行不到）、任务的权重、执行的周期等。
    - 死锁：互相等着对方释放资源，结果谁也得不到
    - 活锁：指线程虽然没有被阻塞，但由于某种条件不满足，一直尝试重试却始终失败。

- 字节在内存中存储方式

  小端法(Little-Endian)就是低位字节排放在内存的低地址端(即该值的起始地址),高位字节排放在内存的高地址端

  大端法(Big-Endian)就是高位字节排放在内存的低地址端(即该值的起始地址),低位字节排放在内存的高地址端

  多字节数值在发送之前,在内存中因该是以大端法存放的，但X86 系列 CPU都是 little－endian 的，

  UDP/TCP/IP协议规定:把接收到的第一个字节当作高位字节看待,这就要求发送端发送的第一个字节是高位字节

- 软硬链接

  http://www.ruanyifeng.com/blog/2011/12/inode.html

- 实例模式和保护模式

#### 进程与线程

- 进程分为基本的三个状态：运行、就绪、阻塞/**等待**
  - 高优先级抢占CPU，状态由运行->就绪
  - 阻塞的进程等待某一条件满足，一旦满足，阻塞->就绪
  - 时间片结束时，状态由运行->就绪
  - 自旋锁（spinlock）是一种保护临界区最常见的技术，没有获得自旋锁的进程在获取锁之前处于忙等（**阻塞**状态）

- 父子进程间

  - 二者并**不共享地址空间**
  - 子进程得到的是除了**代码段**是与父进程共享的以外，其他所有的都是得到父进程的一个**副本**，子进程的所有资源都继承父进程
  - 

- 线程与进程

  - 进程：

    - 进程控制块(PCB)是用来记录进程状态及其他相关信息的数据结构,PCB是进程存在的唯一标志，PCB存在则进程存在。系统创建进程时会产生一个PCB，撤销进程时，PCB也自动消失。

  - 线程有自己的栈（局部变量），但是共享text、static和堆

  - **线程之间没有单独的地址空间**

  - 进程间通信方式

    1.管道

    2.信号量

    3.消息队列

    4.信号

    5.共享内存

    6.套接字

    7.文件和记录锁定

  - 线程和进程的区别联系
    - 进程：子进程是父进程的复制品。子进程获得父进程数据空间、堆和栈的复制品。
    - 线程：相对与进程而言，线程是一个更加接近于执行体的概念，它可以与同进程的其他线程共享数据，但**拥有自己的栈空间**（保存其运行状态和局部自动变量），拥有独立的执行序列。   
    - 根本区别就一点：多进程每个进程有自己的地址空间(address space)，线程则共享地址空间。所有其它区别都是由此而来的： 
      1、速度：线程产生的速度快，线程间的通讯快、切换快等，因为他们在同一个地址空间内。 
      2、资源利用率：线程的资源利用率比较好也是因为他们在同一个地址空间内。 
      3、同步问题：线程使用公共变量/内存时需要使用同步机制还是因为他们在同一个地址空间内
  - 调用线程的sleep()方法,可以使比当前线程优先级低的线程获得运行机会
  - yield()方法使得当前的线程让出CPU的使用权，以使得比该线程优先级相同或更高的线程有机会运行。该线程在让出CPU使用权之后可能再次被选中，因此yield()方法可能会不起作用(这也说明了yield()方法不会使得比当前线程优先级低的线程运行)。
  - 

- 从n个数中找出最小的k个数

  对前k个数，建立最大堆，对于后面N-k个数，依次和最大堆的最大数比较，如果小于最大数，则替换最大数，并重新建立最大堆。时间复杂度为O(N*logk)。当k和N都很大时，这种算法比前两种算法要快很多。

- ==比较内存地址，equals方法比较值

### C++

- 构造函数和析构函数

### 数据结构

- 红黑树

  性质1. 节点是红色或黑色。

  性质2. 根节点是黑色。

  性质3 每个叶节点（NIL节点，空节点）是黑色的。

  性质4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)

  性质5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

### 数据库

#### 数据库设计范式

- 函数依赖

  同一张表中存在部分函数依赖和传递函数依赖的话，会出现数据数据冗余量大，插入异常，删除异常，修改异常等问题

  - 完全函数依赖若X->Y，且对于任何X的子集X‘，Y均不函数依赖于X‘，即X‘->Y不成立

  - 部分函数依赖，X->Y,但Y并不完全函数依赖于X（存在冗余主码，显然码加上任何属性不会构成 新的候选码）

  - 传递函数依赖：传递函数依赖会导致数据冗余和异常。传递函数依赖的Y和Z子集往往同属于某一个事物，因此可将其合并放到一个表中。

    第二范式可以减少部分冗余，非主属性可以分表存储

- 第一范式：符合1NF的关系中的每个属性都不可再分，即字段是最小的单元，不可再分

  关系模式（schema）-关系

- 第二范式：消除**非主属性**对于**码**的**部分函数依赖**。

  - 码：k为表中的一个属性或者属性组，若除k外的所有属性**完全函数依赖**于k，那么称k为候选码（简称码），一张表可以有超过一个码，为了方便，通常会选择一个作为主码【一个码添加其他属性便不再构成码，违反完全函数依赖设定】
  - 非主属性：包含在任何一个码中的属性为主属性

- 第三范式：3NF在2NF的基础之上，消除了**非主属性**对于**码**的**传递函数依赖**

  非主属性不能完全函数依赖于非主属性

  解决删除异常、修改异常和插入异常，数据冗余更少

  由此可见，符合3NF要求的数据库设计，**基本**上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。

- BCNF

  满足3NF的设计仍可能存在插入，修改与删除异常的问题，这是因为存在主属性对码存在部分函数依赖或传递函数依赖关系

#### 事务

不一致现象：

脏读，不可重复读，幻读，具体参见设计数据密集型系统事务一章

隔离级别：

- 读未提交
- 读已提交
- 可重复读
- 序列化

#### 数据库引擎

存储引擎



#### 数据库索引

- 调用函数后，就不会用到索引，查询速度变慢

  - 增加索引会增加磁盘占用
  - 建立索引可以提升查询速度，即读速度；但在一定程度上降低写速度
  - 数据库一般使用B*树作为索引
  - 删除数据需要调整索引，所以会降低效率

- **复合索引可以只使用复合索引中的一部分，但必须是由最左部分开始，且可以存在常量。**

  选择题中常用来考察不同查询条件的效率问题

### java陷阱

- String和String Buffer实现

- 子类继承父类的方法是，控制符必须大于或等于父类的访问控制符

- 重写方法不能比被重写方法限制有更严格的访问级别

- 重写方法不能抛出新的异常或者比被重写方法声明的检查异常更广的检查异常。但是可以抛出更少，更有限或者不抛出异常。

- 接口定义

  - static方法在interface中要有body
  - private修饰的方法不可以出现在interface中

- start启动线程，在某个时间会调用run方法，而直接调用run方法则会直接顺序执行了

- java回收算法

  整个java的垃圾回收是新生代和年老代的协作，这种叫做分代回收。

  - 两个基本的回收算法

    - 标记算法

      一块区域，标记可达对象（可达性分析），然后回收不可达对象，会出现碎片，那么引出

      - 标记整理算法

        多了碎片整理，整理出更大的内存放更大的对象

    - 复制算法

      两个区域A和B，初始对象在A，继续存活的对象被转移到B。此为新生代最常用的算法

  - 新生代和永久代

    - 新生代：初始对象，生命周期短的
    - 永久代：长时间存在的对象

  - 不同的收集器

    - 新生代收集器使用的收集器：Serial、PraNew、Parallel Scavenge

      - Serial New （复制算法）针对新生代的单线程收集器，采用的是复制算法
      - Parallel New（**ParNew**）**(停止-复制算法)**新生代收集器，可以认为是Serial收集器的多线程版本,在多核CPU环境下有着比Serial更好的表现。
      - Parallel Scavenge（复制算法）并行收集器针对新生代，采用复制收集算法

    - 老年代收集器使用的收集器：Serial Old、Parallel Old、CMS

      - Serial Old（标记整理）老年代单线程收集器，Serial收集器的老年代版本。
      - **Parallel Old收集器(标记－整理算法)**
      - **CMS(Concurrent Mark Sweep)收集器（标记-清理算法）**

  **综上：新生代基本采用复制算法，老年代采用标记整理算法。cms采用标记清理。**

### 网络

- Http会话的四个过程:

  建立连接，发送请求，返回响应，关闭连接。

- TIME_WAIT

  客户端主动关闭连接时，会发送最后一个ack后，然后会进入TIME_WAIT状态，再停留2个MSL时间(后有MSL的解释)，进入CLOSED状态。

- OSI七层结构

  - 表示层解决用户信息的语法表示
  - 会话层对数据传输进行管理
  - 每一层传递的数据包

  ​    **物理层：**通过媒介传输比特,确定机械及电气规范（比特Bit）

  ​    **数据链路层**：将比特组装成帧和点到点的传递（帧Frame）

  ​    **网络层**：负责数据包从源到宿的传递和网际互连（包PackeT）

  ​    **传输层**：提供端到端的可靠报文传递和错误恢复（段Segment）

  ​    **会话层**：建立、管理和终止会话（会话协议数据单元SPDU）

  ​    **表示层**：对数据进行翻译、加密和压缩（表示协议数据单元PPDU）

  ​    **应用层**：允许访问OSI环境的手段（应用协议数据单元APDU）

​	

- post和get

  | 操作方式 | 数据位置 | 明文密文 | 数据安全 | 长度限制         | 应用场景 |
  | -------- | -------- | -------- | -------- | ---------------- | -------- |
  | GET      | HTTP包头 | 明文     | 不安全   | 长度较小         | 查询数据 |
  | POST     | HTTP正文 | 可明可密 | 安全     | 支持较大数据传输 | 修改数据 |

- MTP：简单邮件传输协议，使用TCP连接，端口号为25，
  SNMP：简单网络管理协议，使用UDP 161端口，

- 网络层协议包括： IP协议、ICMP协议、ARP协议、RARP协议；
  传输层协议包括：TCP协议、UDP协议

- 物理层：RJ45、CLOCK、IEEE802.3 

  数据链路：PPP、FR、HDLC、VLAN、MAC 

  网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP

  传输层：TCP、UDP、SPX

  会话层：NFS、SQL、NETBIOS、RPC

  表示层：JPEG、MPEG、ASII

  应用层：FTP（文件传送协议）、Telenet（远程登录协议）、DNS（域名解析协议）、SMTP（邮件传送协议），POP3协议（邮局协议），HTTP协议， SNMP协议， TFTP。

### 设计模式


A单例模式没有提高扩展性

B工厂方法实现松耦合，可以提高扩展性

C适配器模式可以将一个接口转换成另一个接口，方便引入外部接口

D装饰者模式可以扩展接口功能

### 计算机操作系统

https://wizardforcel.gitbooks.io/think-os/content/ch11.html

1. 编译
   1. 编译和解释语言
   2. 静态类型
   3. 编译过程
   4. 目标代码
   5. 汇编代码
   6. 预处理
   7. 理解错误
2. 进程
   1. 抽象和虚拟化
   2. 隔离
   3. UNIX进程
3. 虚拟内存
   1. 简明信息理论
   2. 内存和存储
   3. 地址空间
   4. 内存段
   5. 静态局部变量
   6. 地址转换
4. 文件和文件系统
   1. 磁盘性能
   2. 磁盘元数据
   3. 块分配
   4. 一切都是一个文件？
5. 更多的位和字节
   1. 表示整数
   2. 位运算符
   3. 表示浮点型数
   4. 合并和内存错误
   5. 表示字符串
6. 内存管理
   1. 内存错误
   2. 内存泄露
   3. 实现
7. 缓存
   1. 程序如何运行
   2. 缓存性能
   3. 局部性
   4. 衡量缓存性能
   5. 缓存性能编程
   6. 内存层次结构
   7. 缓存策略
   8. 分页
8. 多任务
   1. 硬件状态
   2. 上下文转换
   3. 进程的生命周期
   4. 调度
   5. 实时调度
9. 线程
   1. 创建线程
   2. 同上
   3. 加入线程
   4. 同步错误
   5. 互斥
10. 条件变量
    1. 工作队列
    2. 生产者和消费者
    3. 互斥
    4. 条件变量
    5. 条件变量的实现
11. c中的信号量(Semaphores)
    1. POSIX信号量
    2. 生产者和消费者的信号量
    3. 创建自己的信号量



1. #### 编译

   1. ##### 编译和解释语言

   2. ##### 静态类型

      - “静态”指那些在编译时发生的事情，而“动态”指在运行时发生的事情。
      - 在编译语言中，变量的名称只存在于编译时，而不是运行时。编译器为每个变量选择一个位置，并记录这些位置作为所编译程序的一部分。变量的位置被称为“地址”。在运行期间，每个变量的值都储存在它的地址处，但是变量的名称完全不会储存（除非它们由于调试目的被编译器添加）

   3. ##### 编译过程

      - 预处理

      - 解析

        将程序读进内存中，构建语法树

      - 静态检查

        检查类型

      - 代码生成

      - 链接

      - 优化

   4. ##### 目标代码

      机器码

   5. ##### 汇编代码

      汇编代码——机器代码的可读形式

   6. ##### 预处理

   7. ##### 理解错误

      段错误——读写内存的不正确位置——

2. #### 进程

   1. ##### 抽象和虚拟化

      - 抽象

        抽象是复杂事物的简单表示

      - 虚拟化

        在虚拟化的语境中，我们通常把真实发生的事情叫做“物理的”，而把虚拟上发生的事情叫做“逻辑的”或者“抽象的”。

   2. ##### 隔离

      操作系统最重要的目标之一，就是将每个进程和其它进程隔离，使程序员不必考虑每个可能的交互情况。提供这种隔离的软件对象叫做进程（Process）。 

      进程是包含以下数据的对象：

      - 程序文本
      - 数据相关数据
      - 任何等待中的I/O状态
      - 程序的硬件状态

      进程和程序的关系

      - 通常一个进程运行一个程序，但是对于进程来说，加载并运行新的程序也是可能的。 
      - 多于一个进程中运行相同的程序，这非常常见。这种情况下，各个进程**共享程序文本**，但是**拥有不同的数据和硬件状态**。

   3. ##### UNIX进程

3. #### 虚拟内存

   1. ##### 简明信息理论

   2. ##### 内存和存储器

   3. ##### 地址空间

      - 主存中的每个字节都由一个“物理地址”整数所指定，物理地址的集合叫做物理“地址空间”。它的范围通常为0到`N-1`，其中`N`是主存的大小。
      - 虚拟内存

   4. ##### 内存段

      一个运行中进程的数据组织为4个段：

      - text
      - static
      - stack
      - heap

      这些段的组织方式部分取决于编译器，部分取决于操作系统。不同的操作系统中细节可能不同，但是下面这些是共同的：

      - text段靠近内存“底部”，即接近0的地址
      - static段通常刚好在text段上方
      - stack段靠近内存顶部，即接近虚拟地址空间的最大地址。在扩张过程中，它向低地址的方向增长
      - heap通常在static段的上面。在扩张过程中，它向高地址的方向增长

      通过下面这段程序来看不同段在内存中的实际地址

      ```c
      #include <stdio.h>
      #include <stdlib.h>
      
      int global;
      
      int main ()
      {
          int local = 5;
          int local2 = 5;
      
          void *p = malloc(128);
          void *p2 = malloc(128);
      
          printf ("Address of main is %p\n", main);
          printf ("Address of global is %p\n", &global);
          printf ("Address of local is %p\n", &local);
          printf ("Address of local2 is %p\n", &local2);
          printf ("Address of p is %p\n", p);
          printf ("Address of p2 is %p\n", p2);
          
          return 0;
      }
      ```

      输出

      ```shell
      Address of main is 0x104ee7e20
      Address of global is 0x104ee8020
      Address of local is 0x7ffeead18668
      Address of local2 is 0x7ffeead18664
      Address of p is 0x7fbc38c02890
      Address of p2 is 0x7fbc38c02910
      ```

      - main是函数的名称，当它用作变量时，它指向main中第一条机器语言指令的地址，即认为它在text段中
      - global是一个全局变量，它在static段内
      - local是一个局部变量，它在栈上，同时比较local和local2的地址，可以发现，地址从高地址向低地址方向增长
      - p持有malloc所返回的地址，它指向**堆区**所分配的空间，比较p和p2在内存中的地址，可以发现，地址从低地址向高地址方向增长

   5. ##### 静态局部变量

      静态局部变量在程序启动时初始化，和全局变量一起分配在static段中

   6. ##### 地址转换

4. #### 文件和文件系统

   1. ##### 磁盘性能

      相比cpu的始终周期来说很慢，所以通常在进行io传输时，cpu会切换到别的进程

   2. ##### 磁盘元数据

   3. ##### 块分配

   4. ##### 一切都是一个文件？

5. #### 更多的位和字节

   1. ##### 表示整数

      计算机以补码形式表示数字

   2. ##### 位运算符

      通常，`&`用于清除位向量中的一些位，`|`用于设置位，`^`用于反转位

   3. ##### 浮点数的表示

      在32位的标准中，最左边那位是符号位，`s`。接下来的8位是指数`q`，最后的23位是系数`c`。浮点数的值为：

      ```shell
      (-1) ** s * c * 2 ** q
      ```

   4. ##### 合并和内存错误

   5. ##### 表示字符串

6. #### 内存管理

   1. ##### 内存错误

   2. ##### 内存泄露

      如果你分配了一块内存并且没有释放它，就会产生“内存泄漏”

   3. ##### 实现

7. #### 缓存

   1. ##### 程序如何运行

   2. ##### 缓存性能

      - 缓存命中率h：内存访问时，在缓存中找到数据的比例

      - 缓存缺失率m：内存访问中需要访问内存的比例

        缓存的“命中率”`h`，是内存访问时，在缓存中找到数据的比例。“缺失率”`m`，是内存访问时需要访问内存的比例。如果`Th`是处理缓存命中的时间，`Tm`是缓存未命中的时间，每次内存访问的平均时间是：

        ```
        h * Th + m * Tm
        ```

        同样，我们可以定义“缺失惩罚”，它是处理缓存未命中所需的额外时间，`Tp = Tm - Th`，那么平均访问时间就是：

        ```
        Th + m * Tp
        ```

   3. ##### 局部性

      程序使用相同数据多于一次的倾向叫做“时间局部性”。使用相邻位置的数据的倾向叫做“空间局部性”。 

   4. ##### 衡量缓存性能

      > **单位（Unit）**
      > 位 bit b
      > 字节 byte B
      > 字 word W
      > 字长 word size/length
      > CPU 一次并行处理的二进制位数（通常为 32/64 位）
      > **32 位 CPU：1 Word = 4 Bytes = 32 bits**
      > **64 位 CPU：1 Word = 8 Bytes = 64 bits**
      > **地址的三个域**
      > 设块大小（Cache Block Size）为 B，Cache 组数（Cache Sets）为 S
      > 块数 = Cache 容量（Cache Size）／块大小（Cache Block Size）
      > Cache 组数（Cache Sets） = 块数（Cache Blocks）／路数（Way）
      > tag = 地址总位数（单位为 bits） - index - offset bits
      > index = log2S bits（全相联(full-associative)时，组数(Cache Sets)为0）
      > offset = log2B bits（B 单位为 Byte）
      > PS: Cache Block 与 Cache Line 同义

      一个有趣的练习

      估算电脑缓存大小,缓存块大小，如果数组比缓存大小更小，或步长小于块的大小，我们认为会有良好的缓存性能。如果数组大于缓存大小，并且步长较大时，性能只会下降。

   5. ##### 缓存性能编程

      缓存感知

   6. ##### 存储器层次结构

      | 设备   | 访问时间 | 通常大小 | 成本        |
      | ------ | -------- | -------- | ----------- |
      | 寄存器 | 0.5 ns   | 256 B    | ?           |
      | 缓存   | 1 ns     | 2 MiB    | ?           |
      | DRAM   | 10 ns    | 4 GiB    | $10 / GiB   |
      | SSD    | 10 µs    | 100 GiB  | $1 / GiB    |
      | HDD    | 5 ms     | 500 GiB  | $0.25 / GiB |
      | 磁带   | minutes  | 1–2 TiB  | $0.02 / GiB |

      - 寄存器的数量和大小取决于体系结构的细节。当前的计算机拥有32个通用寄存器，每个都可以储存一个“字”。在32位计算机上，一个字为32位，4个字节。64位计算机上，一个字为64位，8个字节。所以寄存器文件的总容量是100~300字节。 
      - 这些技术构成了“存储器体系结构”。结构中每一级都比它上一级大而缓慢。某种意义上，每一级都作为其下一级的缓存。 你可以认为主存是持久化储存在SSD或HDD上的程序和数据的缓存。并且如果你需要处理磁带上非常大的数据集，你可以用硬盘缓存一部分数据。

   7. ##### 缓存策略

      - 需要强调四个缓存的基本问题：

        - 谁在层次结构中上移或下移数据？在结构的顶端，寄存器通常由编译器完成分配。CPU上的硬件管理内存的缓存。在执行程序或打开文件的过程中，用户可以将存储器上的文件隐式移动到内存中。但是操作系统也会将数据从内存移动回存储器。在层次结构的底端，管理员在磁带和磁盘之间显式移动数据。
        - 移动了什么东西？通常，在结构顶端的块大小比底端要小。在内存的缓存中，通常块大小为128B。内存中的页面可能为4KiB，但是当操作系统从磁盘读取文件时，它可能会一次读10或100个块。
        - 数据什么时候会移动？在多数的基本的缓存中，数据在首次使用时会移到缓存。但是许多缓存使用一些“预取”机制，也就是说数据会在显式请求之前加载。我们已经见过预取的一些形式了：在请求其一部分时加载整个块。
        - 缓存中数据在什么地方？当缓存填满之后，我们不把一些东西扔掉就不可能放进一些东西。理想化来说，我们打算保留将要用到的数据，并替换掉不会用到的数据。

      - 缓存策略

        - LRU，最近最少使用

          从缓存中移除最久未使用的数据块

   8. ##### 页面调度

      在带有虚拟内存的系统中，操作系统可以将页面在存储器和内存之间移动。

      进程和程序的关系：

      - 系统开辟进程来执行程序，同一个程序可以被多个进程执行

8. #### 多任务

   CPU包含多个核心，也就是说它可以同时运行多个进程。而且，每个核心都具有“多任务”的能力，也就是说它可以从一个进程快速切换到另一个进程，创造出同时运行许多进程的幻象。

   1. ##### 硬件状态

   2. ##### 上下文转换

   3. ##### 进程的生命周期

   4. ##### 调度

   5. ##### 实时调度

9. #### 线程

   - 在单一进程中，所有线程都共享相同的`text`段，所以它们运行相同的代码。但是不同线程通常运行代码的不同部分
   - 同时它们间共享相同的static段和堆区
   - **每个线程都有自己的栈**

   1. ##### 创建线程

   2. ##### 同上

   3. ##### 回收线程

      join等待线程执行完毕并回收

   4. ##### 同步错误

      子线程不加限制访问共享变量，每次你运行这个程序的时候，**线程都会在不同时间点上中断**，或者**调度器可能选择不同的线程来运行**，所以时间序列和结果都是不同的

   5. ##### 互斥

10. #### 条件变量

   1. ##### 工作队列

      在一些多线程的程序中，线程被组织用于执行不同的任务。通常它们使用队列来相互通信，其中一些线程叫做“生产者”，向队列中放入数据，另一些线程叫做“消费者”，从队列取出数据。

   2. ##### 生产者和消费者

      当队列为空时，阻塞消费者；当队列满时，阻塞生产者

   3. ##### 互斥

   4. ##### 条件变量

   5. ##### 条件变量的实现

11. #### c中的信号量(Semaphores)

    1. ##### POSIX信号量

       - 信号量是用于使线程协同工作而不互相影响的数据结构。
         - 信号量的类型表现为结构体
         - 关于此结构体的api：初始化(make_semaphore)，阻塞(semaphore_wait) ，发送(semaphore_signal)
       - 当你将信号量用作互斥体时，通常需要将它初始化为1，来表示互斥体是未锁的。

    2. ##### 生产者和消费者的信号量

    3. ##### 创建自己的信号量

 

### 网络工程师们的计算机体系结构





| TCP                                                          | CPU                                                   |
| ------------------------------------------------------------ | ----------------------------------------------------- |
| TCP发送一连串的数据包                                        | CPU处理一系列指令                                     |
| TCP数据包最终被收到                                          | CPU指令最终会过期                                     |
| TCP会根据窗口大小发送一些列的几个数据包，而不会等待第一个数据包被接收后才行动 | CPU同时处理多个指令，而不是等待第一个指令执行完才行动 |
|                                                              | 指令引用没有缓存在内存地址时                          |
|                                                              |                                                       |
|                                                              |                                                       |
|                                                              |                                                       |
|                                                              |                                                       |
| 分类                                                         | 分类描述                                              |





| 分类 | 分类描述                                       |
| ---- | ---------------------------------------------- |
| 1**  | 信息，服务器收到请求，需要请求者继续执行操作   |
| 2**  | 成功，操作被成功接收并处理                     |
| 3**  | 重定向，需要进一步的操作以完成请求             |
| 4**  | 客户端错误，请求包含语法错误或无法完成请求     |
| 5**  | 服务器错误，服务器在处理请求的过程中发生了错误 |



| 状态码 | 状态码英文名称                  | 中文描述                                                     |
| ------ | ------------------------------- | ------------------------------------------------------------ |
| 100    | Continue                        | 继续。客户端应继续其请求                                     |
| 101    | Switching Protocols             | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |
|        |                                 |                                                              |
| 200    | OK                              | 请求成功。一般用于GET与POST请求                              |
| 201    | Created                         | 已创建。成功请求并创建了新的资源                             |
| 202    | Accepted                        | 已接受。已经接受请求，但未处理完成                           |
| 203    | Non-Authoritative Information   | 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 |
| 204    | No Content                      | 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 |
| 205    | Reset Content                   | 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 |
| 206    | Partial Content                 | 部分内容。服务器成功处理了部分GET请求                        |
|        |                                 |                                                              |
| 300    | Multiple Choices                | 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |
| 301    | Moved Permanently               | 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 |
| 302    | Found                           | 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI |
| 303    | See Other                       | 查看其它地址。与301类似。使用GET和POST请求查看               |
| 304    | Not Modified                    | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |
| 305    | Use Proxy                       | 使用代理。所请求的资源必须通过代理访问                       |
| 306    | Unused                          | 已经被废弃的HTTP状态码                                       |
| 307    | Temporary Redirect              | 临时重定向。与302类似。使用GET请求重定向                     |
|        |                                 |                                                              |
| 400    | Bad Request                     | 客户端请求的语法错误，服务器无法理解                         |
| 401    | Unauthorized                    | 请求要求用户的身份认证                                       |
| 402    | Payment Required                | 保留，将来使用                                               |
| 403    | Forbidden                       | 服务器理解请求客户端的请求，但是拒绝执行此请求               |
| 404    | Not Found                       | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面 |
| 405    | Method Not Allowed              | 客户端请求中的方法被禁止                                     |
| 406    | Not Acceptable                  | 服务器无法根据客户端请求的内容特性完成请求                   |
| 407    | Proxy Authentication Required   | 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 |
| 408    | Request Time-out                | 服务器等待客户端发送的请求时间过长，超时                     |
| 409    | Conflict                        | 服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突 |
| 410    | Gone                            | 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 |
| 411    | Length Required                 | 服务器无法处理客户端发送的不带Content-Length的请求信息       |
| 412    | Precondition Failed             | 客户端请求信息的先决条件错误                                 |
| 413    | Request Entity Too Large        | 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 |
| 414    | Request-URI Too Large           | 请求的URI过长（URI通常为网址），服务器无法处理               |
| 415    | Unsupported Media Type          | 服务器无法处理请求附带的媒体格式                             |
| 416    | Requested range not satisfiable | 客户端请求的范围无效                                         |
| 417    | Expectation Failed              | 服务器无法满足Expect的请求头信息                             |
|        |                                 |                                                              |
| 500    | Internal Server Error           | 服务器内部错误，无法完成请求                                 |
| 501    | Not Implemented                 | 服务器不支持请求的功能，无法完成请求                         |
| 502    | Bad Gateway                     | 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求   |
| 503    | Service Unavailable             | 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 |
| 504    | Gateway Time-out                | 充当网关或代理的服务器，未及时从远端服务器获取请求           |
| 505    | HTTP Version not supported      | 服务器不支持请求的HTTP协议的版本，无法完成处理               |



### 计算机组成原理

存储程序概念是冯·诺依曼等人在1946年6月首先提出来的，它可以简要地概括为以下 几点: 

1. 计算机(指硬件)应由运算器、存储器、控制器、输入设备和输出设备五大基本部 件组成; 
2. 计算机内部采用二进制来表示指令和数据;
3. 将编好的程序和原始数据事先存入存储器中，然后再启动计算机工作，这就是存储程序的基本含义。

![](/media/files/images/sc_51.png)

- 运算器和控制器合称为中央处理器CPU

- 中央处理器和主存储器（内存储器）一起组成主机部分

- 三级存储系统

  - 高速缓冲存储器

    存取速度比主存更快，但是容量更小

  - 主存储器

  - 辅助存储器

  三级系统可再划分为两个层次：

  - Cache存储系统

    高速缓存和主存

  - 虚拟存储系统

    主存和辅村

- 计算机执行过程实例

  ![](/media/files/images/sc_52.png)

### 系统设计

#### 可扩展性

- 垂直扩展
- 水平扩展
- 缓存
- 负载均衡
- 数据库复制
- 数据库分区

**高阶的权衡和取舍**

- 性能与可扩展性
- 延迟与吞吐量
- 可用性与一致性

#### 性能与可扩展性

- 如果你的系统有**性能**问题，对于单个用户来说是缓慢的。
- 如果你的系统有**可扩展性**问题，单个用户较快但在高负载下会变慢。

#### 延迟与吞吐量

- **延迟**是执行操作或运算结果所花费的时间。

- **吞吐量**是单位时间内（执行）此类操作或运算的数量。

通常，你应该以**可接受级延迟**下**最大化吞吐量**为目标。

#### 可用性与一致性

- CAP理论（consistency,availability,Partition Tolerance）

  - 在一个分布式计算系统中，只能同时满足下列的两点:

    - **一致性** ─ 每次访问都能获得最新数据但可能会收到错误响应
    - **可用性** ─ 每次访问都能收到非错响应，但不保证获取到最新数据
    - **分区容错性** ─ 在任意分区网络故障的情况下系统仍能继续运行

    **网络并不可靠，所以你应要支持分区容错性，并需要在软件可用性和一致性间做出取舍。**

  - CP ─ 一致性和分区容错性

  - AP ─ 可用性与分区容错性

- 一致性模式

  - 弱一致性
  - 最终一致性
  - 强一致性

- 可用性模式

  - 故障切换（fail-over）
    - 工作到备用切换（Active-passive）
    - 双工作切换（Active-active）
    - 缺陷
      - 故障切换需要添加额外硬件并增加复杂性
      - 如果新写入数据在能被复制到备用系统之前，工作系统出现了故障，则有可能会丢失数据
  - 复制（replication）
    - 主从复制
    - 主主复制

#### 域名系统



#### 内容分发网络（CDN）

内容分发网络（CDN）是一个全球性的代理服务器分布式网络，它从靠近用户的位置提供内容。通常，HTML/CSS/JS，图片和视频等静态内容由 CDN 提供。

#### 负载均衡器

#### 反向代理

#### 应用层

##### 微服务

可以被描述为一系列可以独立部署的小型的，模块化服务。每个服务运行在一个独立的线程中，通过明确定义的轻量级机制通讯，共同实现业务目标。



微服务中的关键技术挑战

- 服务间通信
  - http
  - 异步消息
- 分布式数据管理



缓存-遗漏，乱序执行，流水线执行



编程基本功扎实，掌握C/C++/JAVA等开发语言、常用算法和数据结构；<br/>熟悉TCP/UDP网络协议及相关编程、进程间通讯编程；<br/>了解Python、Shell、Perl等脚本语言；<br/>了解MYSQL及SQL语言、编程，了解NoSQL,&nbsp;key-value存储原理；<br/>全面、扎实的软件知识结构，掌握操作系统、软件工程、设计模式、数据结构、数据库系统、网络安全等专业知识；<br/>了解分布式系统设计与开发、负载均衡技术，系统容灾设计，高可用系统等知识。

### 后台开发面试

- TCP/UDP

  三次招手

  四次挥手

  redis

  redis关键的一个特性：redis的单线程的

  - 面试题
    - redis数据结构
      - 分布式锁的可重入性

  - 应用 布隆过滤器

### 常用linux指令

### Python中的一些语法细节

#### 注意事项

- **永远不要使用小数比较结果来作为两者相等的判断依据**

  可以采取`abs(a-b) < 1e-7`作为二者相等的判断

- `==`操作符比较的是两个变量引用的对象是否具有相同的值

- `is`操作符比较的是两个变量是否引用的是同一个对象

### JAVA

，随即便问了下JAVA多线程技术，线程同步异步、线程安全问题，以及JAVA内存管理的机制

## 构建数据密集型应用(Designing Data-Intensive Application)



**第一部分：数据系统的基石**

讨论设计数据密集型应用所依赖的基本思想

数据密集型体现在三个方面，数据的量，复杂度及数据变化的速度

- 第一章：可靠性、可扩展性、可维护性

  - 讨论我们实际要到达的目标：可靠性(Reliability)，可扩展型(Scalability)，可维护性(Maintainability)；
  - 我们该如何思考这些概念；
  - 以及如何实现他们

- 第二章：数据模型与查询语言

  比较不同的数据模型和查询语言，看看他们如何适用于不同的场景

- 第三章：存储与检索

  讨论存储引擎：数据库如何在磁盘上摆放数据，以及如何高效地再次找到它

- 第四章：编码与演化

  数据编码（序列化），以及随时间演化的模式。

**第二部分：分布式数据**

讨论存储在一台机器上的数据转向讨论分布在多台机器上的数据，这对于可扩展性是必须的，但带来各种独特的挑战

- 第五章：复制

- 第六章：分区

- 第七章：事务

- 第八章：分布式系统的麻烦

  探索关于分布式系统的更多细节

- 第九章：一致性与共识

  分布式系统中实现一致性与共识意味着什么
  **第三部分：衍生数据**

讨论那些从其他数据集衍生出一些数据集的系统。衍生数据经常出现在异构系统中：当没有单个数据库可以把所有事情都做的很好时，应用需要集成几种不同的数据库，缓存，索引等。

- 第十章：批处理

- 第十一章：流处理

- 第十二章：数据系统的未来

  讨论在将来构建可靠，可伸缩和可维护的应用程序



### 第一部分：数据系统的基石

讨论设计数据密集型应用所依赖的基本思想

#### 第一章：可靠性、可扩展性、可维护性

数据密集型应用通常由标准组件构成，标准组件提供了很多通用功能：

- 数据库

- 消息队列

- 缓存

- 搜索索引

- 流处理

- 批处理

  ![](/media/files/images/sc_45.png)

- ##### 可靠性

- ##### 可扩展性

  ###### 负载

  推特业务为例

  - 发布推文

    ![](/media/files/images/sc_46.png)

  - 主页时间线

    ![](/media/files/images/sc_47.png)

  **在早期创业公司或非正式产品中，通常支持产品快速迭代的能力要比可扩展至未来的假想负载要重要的多。**

- 可维护性

  - 可操作性（Operability）
  - 简单性(Simplicity)
  - 可演化性(Evolability)

#### 第二章：数据模型与查询语言

比较不同的数据模型和查询语言，看看他们如何适用于不同的场景

- 关系数据库与文档数据库对比

  当存在多对多关系时，需要在应用程序代码中模拟连接，这通常会比数据库内的专用代码执行的连接慢。

**数据查询语言**

- web上的声明式查询

  在web浏览器中，使用声明式css样式比使用js命令式的操作样式要好的多，类似地，在数据库中，使用sql这样的声明式查询语言比使用命令式查询api要好。

- mapreduce查询

  mapreduce在分布上查询上并不具有垄断

  编程模型

- 图数据模型

#### 第三章：存储与检索

讨论存储引擎：数据库如何在磁盘上摆放数据，以及如何高效地再次找到它

事务性负载和分析性负载（列存储）

两大类存储引擎：

- 日志结构(log-structured)
- 面向页面(page-oriented)

##### 驱动数据库的数据结构

- 哈希索引

- SSTables（Sorted String Table） and LSM-Trees

- BTree

  比上面3者更为常用

- 事务处理和分析系统

  ![](/media/files/images/sc_48.png)

- 数据仓库

  数据仓库包含公司所有各种OLTP系统中的只读数据副本。从OLTP数据库中提取数据（使用定期的数据转储或连续的更新流），转换成适合分析的模式，清理并加载到数据仓库中。

  将数据存入仓库的过程称为“抽取-转换-加载”(ETL)

- OLTP数据库和数据仓库之间的分歧

![](/media/files/images/sc_49.png)

- 数据仓库

  - 下钻：统计维度降到更低的层次，如从季度到月份，数据更细致
  - 上卷：下钻反过程，汇总数据
  - 切片：某些维度固定值
  - 切块：某些维度固定区间

- 星型和雪花型：分析的模式

  星型：![](/media/files/images/sc_50.png)

- 列存储

  Parquet【57】

  Vertical【62】

  OLTP数据库和文档数据库存储都是以面向行的形式进行布局

  > Cassandra和HBase从Bigtable继承，仍然是面向行的

  - 写入列存储

#### 第四章：编码与演化

数据编码（序列化），以及随时间演化的模式。

几种编码数据的格式，包括JSON，XML，Protocol Buffers，Thrift和Avro，以及这些格式如何应对模式变化，及利用这些格式进行数据存储和通信：REST，RPC（Remote Procedure Call，远程过程调用）以及消息传递系统（actors和消息队列）。

使用某种语言的内置编码通常不是一个好主意。

- 向前和向后兼容性

##### 数据如何在流程之间流动的一些最常见的方式

- 数据库中的数据流

  微服务架构：一个关键的设计目标就是通过使服务独立部署和演化来使应用程序更易于更改和维护。

- web service

  - REST，SOAP

    > 在编程中，一个幂等操作的特点是任意多次执行所产生的影响与一次执行的影响相同；幂等函数或幂等方法是指可以用相同方法重复运行，并能获得相同结果的函数。

    - REST强调简单的数据格式，使用url来标示资源，并使用http功能进行缓存控制，身份验证和内容协商

  - RPC

  - 异步消息传递

### 第二部分：分布式数据

讨论存储在一台机器上的数据转向讨论分布在多台机器上的数据，这对于可扩展性是必须的，但带来各种独特的挑战。

导致需要将数据分布到多台机器上有多种多样：可扩展性，容错/高可用性，延迟等

##### 扩展至更高的载荷

- 共享架构

  - 共享内存

  - 共享磁盘架构

    机器使用独立的处理器和内存，但是数据存储在机器之间共享的磁盘阵列上，这些磁盘通过快速网络连接（网络附属存储，NAS；存储区网络SAN）

- 无共享架构

  有时称为水平扩展，每个节点只使用各自的处理器，内存和磁盘。节点之间的任何协调，都是在软件层面使用传统网络实现的。

- 复制VS分区

  - 复制

    在几个不同的节点上保存数据的相同副本。复制提供了冗余：如果一些节点不可用，剩余的节点仍然可以提供数据服务。

  - 分区

    将一个大型数据库拆分成较小的子集，从而不同的分区可以指派给不同的节点。



#### 第五章：复制

同步不同的复制数据间的更改

- 处理节点宕机
  - 从库失效：追赶恢复
  - 主库失效：故障转移

#### 第六章：分区

![](/media/files/images/sc_60.png)



#### 第七章：事务

如果没有事务处理，各种错误情况（进程崩溃，网络断电，停电，磁盘已满，意外并发等）意味着数据可能以各种方式变得不一致。

- 你是否需要事务

- 几个广泛使用的隔离级别：

  - 读已提交
  - 快照隔离
  - 可序列化

- 竞争条件的各种例子

  - 脏读(dirty  reads)

    定义：一个客户端读取到另一个客户端尚未提交的写入

    方法：读已提交或更强的隔离级别可以防止脏读

  - 脏写(dirty  writes)

    定义：一个客户端覆盖写入了另一个客户端尚未提交的写入

    方法：几乎所有的事务实现都可以防止脏写

  - 读取偏差（不可重复读）(read skew/nonrepeatable  reads)

    定义：在同一个事务中，客户端在不同的时间点会看见数据库的不同状态。

    方法：快照隔离经常用于解决这个问题，它允许事务从一个特定时间点的一致性快照中读取数据。通常使用多版本并发控制（MVCC）来实现

  - 更新丢失(lost updates)

    定义：两个客户端同时执行读取-修改-写入序列，其中一个写操作，在没有合入另一个写入变更情况下，直接覆盖了另一个写操作的结果，所以导致数据丢失。

    方法：快照隔离的一些实现可以自动防止这种异常，而另些则需要手动锁定。

  - 写偏差(write skew)

    定义：一个事务读取一些东西，根据读取的值作出决定，并将决定写入数据库，但是写入时候，决定的前提不再是真实的。

    方法：可序列化隔离才能防止这种异常。

  - 幻读(phantom reads)

    定义：一个事务读取符合某些搜索条件的对象，另一个客户端进行了影响搜索结果的写入。

    方法：快照隔离可以防止直接的幻像读取，但是在写偏差环境下的幻象读取需要特殊处理，例如索引锁定。

  弱隔离级别可以防止这些异常情况的一部分，剩下的需要应用程序的开发者手动处理这些情况，只有可序列化的隔离才能防范所有这些问题。

  可序列化事务的三种不同实现方法：

  - 字面意义上的串行执行

    如果每个事务的执行速度非常快，并且事务吞吐量足够低，足以在单个cpu核上处理，这是一个简单而有效的选择。

  - 两阶段锁定(teo-phase locking)

    实现可序列化的标准方式，但是许多应用出于性能问题的考虑避免使用它。

  - 可串行化快照隔离(Serializable Snapshot Isolation, SSI)

    允许事务执行而无需阻塞。当一个事务想要提交时，它会进行检查，如果没有序列化，事务就会被中止。



##### mysql的事务隔离级别

| 级别名   | 级别号 | 脏读 | 不可重复读 | 错误读取 |
| -------- | ------ | ---- | ---------- | -------- |
| 读未提交 | 0      | 1    | 1          | 1        |
| 读提交   | 1      | 0    | 1          | 1        |
| 可重复读 | 2      | 0    | 0          | 1        |
| 可串行化 | 3      | 0    | 0          | 0        |

数据库默认的级别是2级可重复读

读未提交什么都无法保证，读提交可以避免脏读（事务B读取了事务A尚未提交的数据），可重复读可以消除不可重复读（事务A在两次查询的间隙，值被事务B操作改变，此时事务B已提交，A两次的读取出现不一致），但仍会出现幻读，可序列化可以避免这些问题

#### 第八章：分布式系统的麻烦

探索关于分布式系统的更多细节

分布式系统中可能发生的各种问题：

- 尝试通过网络发送数据包时，数据包可能丢失或任意延迟。同样，回复也可能会丢失或延迟，所以如果没有得到答复，你不知道消息是否通过。
- 节点的时钟可能会与其他节点明显不同步，可能会突然跳转或跳回，因为不能很好的衡量时钟错误间隔，所以依赖它是很危险的
- 一个进程可能会在其执行的任何时候暂停一段很长的时间，被其他节点宣告死亡，然后再次复活，却没有意识到它被暂停了。

每当软件软件试图做任何涉及其他节点的事情，偶尔就有可能会失败，或者随机变慢，或者根本没有响应。在分布式系统中，我们试图在软件中建立部分失效的容错机制，这样整个系统即使在某些组成部分被破坏的情况下，也可以继续运行。

- 检测错误
- 如何容忍

从不可靠的组件构建可靠的系统

- 网络的问题

- 时钟和时序问题

- 可以避免的程度

- 进程的不可靠性

- 如何思考一个分布式系统的状态

  分布式系统可以永久运行而不会在服务层面中断，因为所有的错误和维护都可以在节点级别进行处理。

#### 第九章：一致性与共识

分布式系统中实现一致性与共识意味着什么

达成共识意味着以这样一种方式决定某件事：所有节点一致同意所做决定，且这一决定不可撤销。很广泛的一系列问题都可以归结为共识问题，并且彼此等价，这些等价的问题包括：

- 线性一致性的CAS寄存器

  寄存器需要给予当前值是否等于操作给出的参数，原子的决定是否设置新值

- 原子事务提交

  数据库必须决定是否提交或中止分布式事务

- 全序广播

  消息系统必须决定传递消息的顺序

- 锁和租约

  当几个客户端争抢锁或租约时，由锁决定哪个客户成功获得锁。

- 成员/协调服务

  给定某种故障检测器（例如超时），系统必须决定哪些节点活着，哪些节点因为会话超时需要被宣告死亡。

- 唯一性约束

  当多个事务同时尝试使用相同的健创建冲突记录时，约束必须决定哪一个被允许，哪些因为违反约束而失败。

选取新领导的三种方法：

- 等待领导者恢复
- 人工故障切换
- 使用算法自动选择一个新的领导者





### 第三部分：衍生数据

讨论那些从其他数据集衍生出一些数据集的系统。衍生数据经常出现在异构系统中：当没有单个数据库可以把所有事情都做的很好时，应用需要集成几种不同的数据库，缓存，索引等。

应用程序通常组合使用多种组件：数据存储，索引，缓存，分析系统等等，并实现在这些组件中移动数据的机制。



从更高的层次看，存储和处理数据的系统可以分为两大类

- 记录系统

  真相源，持有数据的权威版本。

- 衍生数据系统

  是另一个系统中的现有数据以某种方式进行转换或处理的结果。典型的例子是缓存，索引和物化视图亦属此类。

#### 第十章：批处理

基于一个假设：输入是有界的，即已知和有限的大小

主要有三种不同类型的系统

- 服务（在线系统）
- 批处理系统（离线系统）
- 流处理系统（准实时系统）

批处理算法：Map-Reduce



##### 使用Unix工具进行批处理

- unix工具

  看一个操作实例

  - awk

  - grep

  - uniq

    通过检查两个相邻行是否相同来过滤掉输入中的重复行，-c表示输出一个计数器

  - sort

    -n 按每行起始处的数字排序，-r然后逆序返回结果

- 排序VS内存中的聚合

  hash表和排序的性能取决于不同URL的数量

  - 如果作业的工作集大于可用内存，则排序方法的优点是可以高效的使用磁盘，数据块可以在内存中排序并作为段文件写入磁盘，然后多个排序好的段可合并为一个更大的排序文件。
  - **sort程序通过溢出至磁盘的方式来自动应对大于内存的数据集，并能同时使用多个CPU核进行并行排序**。

- Unix哲学

  - 统一的接口

    文件

    xargs可以指定如何解析输入

  - 逻辑与布线相分离

    将输入/输出与程序逻辑分开，可以将小工具组合成更大的系统，但是**标准的输入和输出能够做的事是非常有限的**。

  - 透明度与实验

unix工具的最大局限在于它们**只能在一台机器上运行**



##### MapReduce和分布式文件系统

- MapReduce作业执行

  - 读取一组输入文件，并将其分解成记录
  - 调用Mapper函数，从每条输入记录中提取一对键值，类似awk提取url作为key
  - 按key排列所有的键值对
  - 调用Reduce函数遍历排序后的键值对。如果同一个键出现多次，排序使它们在列表中相邻，所以很容易组合这些值而不必在内存中保留很多状态。

  **注意**：

  为了确保具有相同键的所有键值对最终落在相同的Reduce处，框架使用**键的散列值**来确定Reduce任务应该接收到特定的键值对。



  键值对必须进行排序，但数据集可能太大，无法在单台机器上使用常规排序算法进行排序，排序是分阶段进行的：首先每个Mapper都按照散列值将输出分区到Reducer，分区到每一个Reducer的数据都分别在Mapper的本地磁盘上写入了一个排序的文件中，只要当Mapper读取完输入文件，并写入到排好序的文件中，此时Reducer从每个Mapper取回（下载）分区到自己的排序文件，整个分区，排序，取回排序文件的过程称为混洗（shuffle）。

> 一旦你有一个合适的键值散列函数，你可以为每个分区分配一个散列范围（而不是键的范围），每个通过哈希散列落在分区内的键将被存储在该分区中。



> 像归并排序一样，对那些已经排好序的文件，并排读取输入文件，查看每文件的第一个键，根据排序规则，复制最低键到输出文件，重复直到合并所有文件到同一文件。

- MapReduce工作流

  单个MR作业解决的问题非常有限，因此将MR作业连接成为工作流是极为常见的。这个链接通过目录名隐式实现。

  - Hadoop的工作流调度器：Oozie，Azkaban，Luigi，Airflow和Pinball
  - Hadoop的各种高级工具pig，Hive，Cascading，Crunch和FlumeJava也支持构建组合多个MR作业的工作流

- Reduce端连接与分组

  mapreduce的连接算法

  - 排序合并连接

    每个Mapper提取的键一样，但是值可能是不一样的Ts

- Map端连接

  - 广播散列连接

    broadcast可以解释为，更大输入在每个Mapper的分区被Mapper完全的读进内存中

  - 分区散列连接
  - Map端合并连接

  - MapReduce工作流与Map端连接

- 批处理工作流的输出

  批处理过程的输出通常不是报表，而是一些其他类型的结构

  - 建立搜索索引：文件关键词字典，关键字及包含关键字的所有文档id列表

  - 键值存储：构建机器学习系统

    - 分类器，比如垃圾邮件过滤器，异常检测，图像识别
    - 推荐系统，你可能认识的人，你可能感兴趣的产品或相关的搜索

  - 批处理输出的哲学

    很多Unix上表现良好的设计原则似乎也适用于Hadoop，但Unix和Hadoop在某些方面也有所不同，Hadoop上可以通过使用更结构化的文件格式消除一些低价值的语法转换，比如**Avro和Parquet——提供了就业模式的高效编码，并允许模式随时间推移而演进**

- Hadoop与其他分布式数据库的对比

  - 存储多样性
  - 处理模型多样性

- 针对频繁故障设计

  任意终止进程的自由有利于提高计算集群中资源利用率

  Yarn的CapacityScheduler支持抢占以平衡不同队列的资源分配

##### MapReduce之后

- 中间状态的物化视图

  一个作业的输出是另一个作业的输入，那么这个输出就是一个中间状态，将中间状态写入文件的过程称为物化

  mapreduce的不足：

  1. 作业之间存在依赖关系
  2. mapper通常是多余的
  3. 中间状态也会被复制到多个节点

  - 数据流引擎

    - spark
    - Tez
    - Flink

    以上三种引擎的设计方式与很多区别，但有一个共同点：把整个工作流作为单个文件处理，而不是把它分解为独立的子作业

- 图和迭代处理

- 高级接口和语言



#### 第十一章：流处理

限制一个架构最大负载量的限制是什么

docker构建spark环境



##### 传递事件流

- 消息系统

- 分区日志


##### 数据库与流

- 保持系统同步

- 获取数据变更

- 事件溯源

- 状态、流和不变性


##### 流处理

- 流处理的应用
- 时间推理
- 流连接
- 容错





**流是指随着时间推移逐渐可用的数据**

事件流视为一种数据管理机制，无界限，增量处理。

##### 消息系统

表示、存储、通过网络传输流

流和数据库之间的关系

连续处理流的方法和工具，用于应用构建的方式



**流处理的几种目的**：

- 搜索事件模式（复杂事件处理）
- 计算分窗聚合（流分析）
- 保证衍生数据系统处于最新状态（物化视图）



流处理中可能出现的三种连接类型：（straem join）

- 流流连接

  两个输入流都由活动事件组成

- 流表连接

  一个输入流由活动事件组成，另一个数据流是数据库变更日志

- 表表连接

  两个输入流都是数据库变更日志



流处理中实现容错和恰好一次语义（exactly-once semantics）的技术



#### 第十二章：数据系统的未来

实然-应然



数据集成

理解数据流



批处理与流处理





讨论在将来构建可靠，可伸缩和可维护的应用程序



如何使用批处理和流处理来解决数据集成问题，以便让数据变更在不同系统间流动

维护索引，物化视图，机器学习模型，统计摘要





**软件和数据对世界产生了如此巨大的影响，我们工程师必须牢记，我们有责任为我们想要的世界而努力：一个尊重人们，尊重人性的世界。**



### 案例

#### 知乎架构变迁史

- PV(page view)，即页面浏览量，或点击量;通常是衡量一个网络新闻频道或网站甚至一条网络新闻的主要指标。pv就是一个访问者打开了你的几个页面。
- uv(unique visitor)，指访问某个站点或点击某条新闻的不同IP地址的人数。
- PR值，即PageRank，网页的级别技术。取自Google的创始人Larry Page，它是Google排名运算法则(排名公式)的一部分，用来标识网页的等级/重要性。级别从1到10级，10级为满分。PR值越高说明该网页越受欢迎(越重要)。
- IP(独立IP)：即Internet Protocol,指独立IP数。



#### Docker核心技术与实现原理

- 命名空间 (namespaces)

  运行在同一台机器上的不同服务能做到**完全隔离**，就像运行在多台不同的机器上一样。

  命名空间为新创建的进程隔离了文件系统、网络，并与宿主机器之间的进程相互隔离

  - 进程

  - 网络

    - Host

    - Container

    - None

    - Bridge

      当 Docker 服务器在主机上启动之后会创建新的虚拟网桥 docker0，随后在该主机上启动的全部服务在默认情况下都与该网桥相连

      - libnetwork

        提供了一个连接不同容器的实现，同时也为应用给出一个能够提供一致的编程接口和网络层抽象的容器网络模型

        - Sandbox

          存储着当前容器的网络栈配置，包括容器的接口、路由表和 DNS 设置，Linux 使用网络命名空间实现这个 Sandbox，每一个 Sandbox 中都可能会有一个或多个 Endpoint，在 Linux 上就是一个虚拟的网卡 veth，Sandbox 通过 Endpoint 加入到对应的网络中，这里的网络可能就是我们在上面提到的 Linux 网桥或者 VLAN

        - Endpoint

        - Network

  - 挂载点

- 控制组（CGroups）

  命名空间不能提供物理资源上的隔离，比如CPU或者内存

- UnionFS（存储驱动）

  后来改到AUFA，目前采用overlay2取代了aufs成为了推荐的存储驱动

  把多个文件系统『联合』到同一个挂载点的文件系统服务

  docker的镜像是如何组织的：每一层镜像都建立在另一层镜像之上，并且镜像都是只读的，每当基于一个镜像新建一个容器时，等于在镜像的最上层添加一个可以读写的层。

- reference

  https://draveness.me/docker





#### Docker入门与实践

> mac版的docker网络配置，mac版封装好了用xhyve创建的虚拟机，这台虚拟机才是docker的宿主机。

https://yq.aliyun.com/articles/40494?spm=a2c4e.11153959.teamhomeleft.95.44ab18b1OELKiS

[mac的例外之处](https://docs.docker.com/docker-for-mac/networking/#use-cases-and-workarounds)

宿主机无法直接和容器互ping，但是可以进行端口xport映射，从而通过localhost:xport访问容器内的服务

- docker run -d -it --rm ubuntu bash 

  - `-it`：这是两个参数，一个是 `-i`：交互式操作，一个是 `-t` 终端。我们这里打算进入 `bash` 执行一些命令并查看返回结果，因此我们需要交互式终端。
  - `--rm`：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 `docker rm`。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 `--rm` 可以避免浪费空间。

  - -d:此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 `docker logs`查看)

- docker commit

- ```bash
  docker commit \
      --author "Changxin Cheng <chengcx1019@gmail.com>" \
      --message "添加了pyspark，可通过python接口调用spark服务" \
      nodemaster \
      sparkbase:v2
  ```

- docker build .  --no-cache -t {image_name}

  - `-t`:镜像的命名和可选的tag标签可以以 'name:tag' 这种形式
  - `.`:代表当前上下文环境，docker引擎会打包上下文内的所有文件进行镜像构建

- docker system df

  查看镜像、容器、数据卷所占用的空间

- docker exec -i -t bash 

##### compose

`docker-compose`



先用docker搭一个zookeeper集群吧

容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。







## spark和hadoop

### spark

以指定版本启动spark:

​	PYSPARK_PYTHON=python3 ./bin/pyspark



jupyter toree install --interpreters=Scala --spark_home=/usr/local/Cellar/apache-spark/2.1.0/libexec --user --kernel_name=apache_toree --interpreters=PySpark,SparkR,Scala,SQL



jupyter扩展插件：

pip install jupyter_contrib_nbextensions
jupyter contrib nbextension install --user
pip install jupyter_nbextensions_configurator
jupyter nbextensions_configurator enable --user

##### spark用例

spark常用操作及实践

- 创建推荐引擎

  ALS协同过滤式推荐算法

  将mxn矩阵分解为mxrank 和rankxn

- 决策树二分类

  - 分类准则

    - 基尼指数：基尼指数最小
      $$
      G_i = 1 - \sum_{k=1}^{n}p_{i,k}^2
      $$
      式中$p_{i,k}$是第i个节点中类别k的比率

    - 熵：选择分裂后熵最小的方式，自然全部分类正确的话熵为0
      $$
      H_i = - \sum_{k=1,p_{i,k}\neq0}^{n}p_{i,k}\log(p_{i,k})
      $$




### hadoop

#### 操作

- 从本地复制文件到hdfs：`hadoop fs -compFromLocal -f sorce dest`


#### 故障排除

- hdfs拒绝连接

  格式化hdfs：`hdfs namenode -format`

- 

